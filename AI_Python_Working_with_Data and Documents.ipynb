{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQxmseSw7YmCv0LQ3SxmJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashg7/AI/blob/main/AI_Data_Documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install openai\n",
        "from google.colab import drive\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = \"\"\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# Load chatGPT\n",
        "def ask_chatgpt(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Load a file\n",
        "def load_file(path):\n",
        "  with open(path, 'r') as file:\n",
        "    text = file.read()\n",
        "  return text\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EDcGiEvFdS2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBiL0ev1YX08",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Mount files\n",
        "\n",
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "# Load the model with GPU\n",
        "pipe = pipeline(task = \"text-classification\", model = \"classla/multilingual-IPTC-news-topic-classifier\", device = 0)\n",
        "\n",
        "for text_file in files:\n",
        "  # Read the file\n",
        "  f = open(path + text_file, \"r\")\n",
        "  text = f.read()\n",
        "  f.close()\n",
        "\n",
        "  # Run the model\n",
        "  classified = pipe(text)\n",
        "  relevancy = \"relevant\" if classified[0]['label'] == 'lifestyle and leisure' else \"irrelevant\"\n",
        "\n",
        "  print(f\"The text {text_file} is {relevancy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"cape_town.txt\"]\n",
        "\n",
        "# Produce html\n",
        "for text_file in files:\n",
        "  # Read the file\n",
        "  f = path + text_file\n",
        "  with open(f,'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "  # Run the model\n",
        "  prompt = f\"\"\"\n",
        "    Produce a html text for the following text: {text}\n",
        "    Highlight in pink the restaurant names and in green the dishes.\n",
        "  \"\"\"\n",
        "  html = ask_chatgpt(prompt)\n",
        "  # Write the answer in a new file\n",
        "  file_path = path + text_file[:-4] + '.html'\n",
        "  with open(file_path, 'w') as file:\n",
        "    file.write(html)\n"
      ],
      "metadata": {
        "id": "X7IYV6Bpq-No",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "file_path = path + 'itinerary.csv'\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "  itinerary = file.read()\n",
        "\n",
        "dic_itinerary = []\n",
        "for row in csv.DictReader(itinerary.splitlines()):\n",
        "  dic_itinerary.append(row)\n",
        "\n",
        "\n",
        "prompt = f\"\"\" I will visit {dic_itinerary[2][\"City\"]} in {dic_itinerary[2][\"Country\"]},\n",
        "from {dic_itinerary[2][\"Arrival\"]} to {dic_itinerary[2][\"Departure\"]}.\n",
        "Please, provide a detailed itinerary for this visit in Markdown format. Do not include any other text at the end.\n",
        "\"\"\"\n",
        "\n",
        "response = ask_chatgpt(prompt)\n",
        "display(Markdown(response))\n"
      ],
      "metadata": {
        "id": "weRene2zx11W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "files_names = [\"itinerary.csv\",\"cape_town.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
        "name_cities = [\"Cape Town\", \"Rio de Janeiro\", \"Sydney\", \"Tokyo\"]\n",
        "\n",
        "#Load files\n",
        "files_content = []\n",
        "for file in files_names:\n",
        "    content = load_file(path + file)\n",
        "    files_content.append(content)\n",
        "\n",
        "itinerary = []\n",
        "for row in csv.DictReader(files_content[0].splitlines()):\n",
        "  itinerary.append(row)\n",
        "\n",
        "files_content = files_content[1:]\n",
        "\n",
        "dict_resto = {}\n",
        "restaurants = {}\n",
        "for content, name in zip(files_content, name_cities):\n",
        "  prompt = f\"\"\"Extract a list with the name of the restaurants and the most famous dish\n",
        "  for each of restaurant in the following text: {content}.\n",
        "  Provide your answer in CSV format, ready to save.\n",
        "  Exclude the csv declaration, don't add spaces after the comma, do not include column headers.\n",
        "  Format:\n",
        "  Res_1, Dish_1\n",
        "  Res_2, Dish_2\n",
        "  ...\n",
        "  \"\"\"\n",
        "  response = ask_chatgpt(prompt)\n",
        "\n",
        "  for row in csv.reader(response.splitlines()):\n",
        "    restaurant, dish = row  # Unpack each row\n",
        "    restaurants[restaurant.strip()] = dish.strip()  # Use restaurant as key and dish as value\n",
        "\n",
        "  name = name.replace(\".txt\", \"\")\n",
        "  dict_resto[name] = restaurants\n",
        "  restaurants = {}\n",
        "\n",
        "travel_itinerary = {}\n",
        "for travel_spot in itinerary:\n",
        "\n",
        "  prompt = f\"\"\"I will travel to {travel_spot['City']} in {travel_spot['Country']},\n",
        "  from {travel_spot['Arrival']} to {travel_spot['Departure']}.\n",
        "  Please, provide a detailed itinerary for this visit in Markdown format. Do not include any other text at the end.\n",
        "  For each day provide a spot for having lunch and for having dinner and choose the restaurant from the following list:\n",
        "  {dict_resto[travel_spot['City']]}. Do not repeate the same restaurant in any of the days and include\n",
        "  the dish for each restaurant.\n",
        "  \"\"\"\n",
        "  travel_itinerary[travel_spot['City']] = ask_chatgpt(prompt)\n"
      ],
      "metadata": {
        "id": "8RDasnnaimeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(travel_itinerary['Tokyo']))"
      ],
      "metadata": {
        "id": "6JbJwMcbx043"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
