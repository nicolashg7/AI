{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQxmseSw7YmCv0LQ3SxmJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashg7/AI/blob/main/AI_Data_Documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install openai\n",
        "from google.colab import drive\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = \"\"\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# Load chatGPT\n",
        "def ask_chatgpt(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Load a file\n",
        "def load_file(path):\n",
        "  with open(path, 'r') as file:\n",
        "    text = file.read()\n",
        "  return text\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EDcGiEvFdS2r",
        "outputId": "cd548fdb-3949-4c39-8a9a-baeda4abd6eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBiL0ev1YX08",
        "outputId": "7ee0bb89-7b2a-4590-c081-5f209349c157",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "The text cape_town.txt is relevant\n",
            "The text madrid.txt is irrelevant\n",
            "The text rio_de_janeiro.txt is relevant\n",
            "The text sydney.txt is relevant\n",
            "The text tokyo.txt is relevant\n"
          ]
        }
      ],
      "source": [
        "# Mount files\n",
        "\n",
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "# Load the model with GPU\n",
        "pipe = pipeline(task = \"text-classification\", model = \"classla/multilingual-IPTC-news-topic-classifier\", device = 0)\n",
        "\n",
        "for text_file in files:\n",
        "  # Read the file\n",
        "  f = open(path + text_file, \"r\")\n",
        "  text = f.read()\n",
        "  f.close()\n",
        "\n",
        "  # Run the model\n",
        "  classified = pipe(text)\n",
        "  relevancy = \"relevant\" if classified[0]['label'] == 'lifestyle and leisure' else \"irrelevant\"\n",
        "\n",
        "  print(f\"The text {text_file} is {relevancy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"cape_town.txt\"]\n",
        "\n",
        "# Produce html\n",
        "for text_file in files:\n",
        "  # Read the file\n",
        "  f = path + text_file\n",
        "  with open(f,'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "  # Run the model\n",
        "  prompt = f\"\"\"\n",
        "    Produce a html text for the following text: {text}\n",
        "    Highlight in pink the restaurant names and in green the dishes.\n",
        "  \"\"\"\n",
        "  html = ask_chatgpt(prompt)\n",
        "  # Write the answer in a new file\n",
        "  file_path = path + text_file[:-4] + '.html'\n",
        "  with open(file_path, 'w') as file:\n",
        "    file.write(html)\n"
      ],
      "metadata": {
        "id": "X7IYV6Bpq-No",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "file_path = path + 'itinerary.csv'\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "  itinerary = file.read()\n",
        "\n",
        "dic_itinerary = []\n",
        "for row in csv.DictReader(itinerary.splitlines()):\n",
        "  dic_itinerary.append(row)\n",
        "\n",
        "\n",
        "prompt = f\"\"\" I will visit {dic_itinerary[2][\"City\"]} in {dic_itinerary[2][\"Country\"]},\n",
        "from {dic_itinerary[2][\"Arrival\"]} to {dic_itinerary[2][\"Departure\"]}.\n",
        "Please, provide a detailed itinerary for this visit in Markdown format. Do not include any other text at the end.\n",
        "\"\"\"\n",
        "\n",
        "response = ask_chatgpt(prompt)\n",
        "display(Markdown(response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "weRene2zx11W",
        "outputId": "5440cb96-ea34-4e02-a521-2706544a595a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Cape Town Itinerary\n\n## Day 1: 17-Jul\n- Arrival at Cape Town International Airport\n- Check into hotel\n- Visit Victoria & Alfred Waterfront for dinner and shopping\n\n## Day 2: 18-Jul\n- Explore Table Mountain National Park\n- Take a cable car up Table Mountain\n- Visit Kirstenbosch Botanical Gardens\n\n## Day 3: 19-Jul\n- Wine tasting tour in Stellenbosch or Franschhoek\n- Visit Groot Constantia or another winery\n- Enjoy lunch at a vineyard\n\n## Day 4: 20-Jul\n- Visit Robben Island\n- Explore the District Six Museum\n- Dinner at a local restaurant\n\n## Day 5: 21-Jul\n- Shark cage diving in Gansbaai\n- Visit Hermanus for whale watching\n- Dinner at a seafood restaurant\n\n## Day 6: 22-Jul\n- Explore Boulders Beach\n- Visit Cape Point and Cape of Good Hope\n- Drive along Chapman's Peak Drive\n\n## Day 7: 23-Jul\n- Explore the Bo-Kaap neighborhood\n- Visit the Two Oceans Aquarium\n- Enjoy dinner at a local seafood restaurant\n\n## Day 8: 24-Jul\n- Check out of hotel\n- Visit Greenmarket Square for souvenirs\n- Depart from Cape Town International Airport"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "files_names = [\"itinerary.csv\",\"cape_town.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
        "name_cities = [\"Cape Town\", \"Rio de Janeiro\", \"Sydney\", \"Tokyo\"]\n",
        "\n",
        "#Load files\n",
        "files_content = []\n",
        "for file in files_names:\n",
        "    content = load_file(path + file)\n",
        "    files_content.append(content)\n",
        "\n",
        "itinerary = []\n",
        "for row in csv.DictReader(files_content[0].splitlines()):\n",
        "  itinerary.append(row)\n",
        "\n",
        "files_content = files_content[1:]\n",
        "\n",
        "dict_resto = {}\n",
        "restaurants = {}\n",
        "for content, name in zip(files_content, name_cities):\n",
        "  prompt = f\"\"\"Extract a list with the name of the restaurants and the most famous dish\n",
        "  for each of restaurant in the following text: {content}.\n",
        "  Provide your answer in CSV format, ready to save.\n",
        "  Exclude the csv declaration, don't add spaces after the comma, do not include column headers.\n",
        "  Format:\n",
        "  Res_1, Dish_1\n",
        "  Res_2, Dish_2\n",
        "  ...\n",
        "  \"\"\"\n",
        "  response = ask_chatgpt(prompt)\n",
        "\n",
        "  for row in csv.reader(response.splitlines()):\n",
        "    restaurant, dish = row  # Unpack each row\n",
        "    restaurants[restaurant.strip()] = dish.strip()  # Use restaurant as key and dish as value\n",
        "\n",
        "  name = name.replace(\".txt\", \"\")\n",
        "  dict_resto[name] = restaurants\n",
        "  restaurants = {}\n",
        "\n",
        "travel_itinerary = {}\n",
        "for travel_spot in itinerary:\n",
        "\n",
        "  prompt = f\"\"\"I will travel to {travel_spot['City']} in {travel_spot['Country']},\n",
        "  from {travel_spot['Arrival']} to {travel_spot['Departure']}.\n",
        "  Please, provide a detailed itinerary for this visit in Markdown format. Do not include any other text at the end.\n",
        "  For each day provide a spot for having lunch and for having dinner and choose the restaurant from the following list:\n",
        "  {dict_resto[travel_spot['City']]}. Do not repeate the same restaurant in any of the days and include\n",
        "  the dish for each restaurant.\n",
        "  \"\"\"\n",
        "  travel_itinerary[travel_spot['City']] = ask_chatgpt(prompt)\n"
      ],
      "metadata": {
        "id": "8RDasnnaimeI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(travel_itinerary['Tokyo']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "6JbJwMcbx043",
        "outputId": "33423412-7180-4370-ba04-96297b2967ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Tokyo Itinerary\n\n## Day 1: 10-Aug\n- **Morning:** Explore Asakusa and visit Senso-ji Temple\n- **Lunch:** Tsukiji Outer Market (Fresh sashimi and street food)\n- **Afternoon:** Visit Tokyo Skytree\n- **Dinner:** Narisawa (Innovative tasting menu)\n\n## Day 2: 11-Aug\n- **Morning:** Visit Meiji Shrine\n- **Lunch:** Ichiran Ramen (Tonkotsu ramen)\n- **Afternoon:** Explore Harajuku and Takeshita Street\n- **Dinner:** Ginza Kojyu (Kaiseki)\n\n## Day 3: 12-Aug\n- **Morning:** Visit Tsukiji Fish Market\n- **Lunch:** Sukiyabashi Jiro (Omakase sushi)\n- **Afternoon:** Explore Odaiba and visit TeamLab Borderless\n- **Dinner:** Akasaka Kikunoi (Kaiseki)\n\n## Day 4: 13-Aug\n- **Morning:** Visit Imperial Palace\n- **Lunch:** Ginza Kojyu (Kaiseki)\n- **Afternoon:** Explore Shibuya and cross the Shibuya Crossing\n- **Dinner:** Tsukiji Outer Market (Fresh sashimi and street food)\n\n## Day 5: 14-Aug\n- **Morning:** Visit Ueno Park and Ueno Zoo\n- **Lunch:** Akasaka Kikunoi (Kaiseki)\n- **Afternoon:** Explore Akihabara\n- **Dinner:** Sukiyabashi Jiro (Omakase sushi)\n\n## Day 6: 15-Aug\n- **Morning:** Visit Tokyo Disneyland or DisneySea\n- **Lunch:** Narisawa (Innovative tasting menu)\n- **Afternoon:** Explore Shinjuku and visit the Tokyo Metropolitan Government Building\n- **Dinner:** Ichiran Ramen (Tonkotsu ramen)\n\n## Day 7: 16-Aug\n- **Morning:** Visit Roppongi Hills\n- **Lunch:** Tsukiji Outer Market (Fresh sashimi and street food)\n- **Afternoon:** Stroll around Omoide Yokocho\n- **Dinner:** Ginza Kojyu (Kaiseki)\n\n## Day 8: 17-Aug\n- **Morning:** Visit Yoyogi Park\n- **Lunch:** Akasaka Kikunoi (Kaiseki)\n- **Afternoon:** Last-minute shopping in Shibuya\n- **Dinner:** Narisawa (Innovative tasting menu)"
          },
          "metadata": {}
        }
      ]
    }
  ]
}